{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Overview - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this binary classification problem, we are using Logistic Regression, Decision Tree Classifier, Random Forest Classifier, and Gradient Boosting Classifier, Gaussian Naive Bayes. To assess the accuracy, we look at the accuracy scores and classification reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import (cross_val_score, GridSearchCV, train_test_split, KFold)\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, plot_precision_recall_curve, precision_recall_curve)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import imblearn\n",
    "from imblearn.under_sampling import (RandomUnderSampler, EditedNearestNeighbours, NearMiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetes_ml_scale.csv', index_col=0) # import data\n",
    "diabetes = data.copy() # save a copy of data as diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 64360 entries, 0 to 64359\n",
      "Data columns (total 64 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   gender                64360 non-null  int64  \n",
      " 1   diabetesMed           64360 non-null  int64  \n",
      " 2   time_in_hospital      64360 non-null  float64\n",
      " 3   num_lab_procedures    64360 non-null  float64\n",
      " 4   num_procedures        64360 non-null  float64\n",
      " 5   num_medications       64360 non-null  float64\n",
      " 6   num_outpatient        64360 non-null  float64\n",
      " 7   num_inpatient         64360 non-null  float64\n",
      " 8   num_diagnoses         64360 non-null  float64\n",
      " 9   change                64360 non-null  int64  \n",
      " 10  AfricanAmerican       64360 non-null  int64  \n",
      " 11  Asian                 64360 non-null  int64  \n",
      " 12  Caucasian             64360 non-null  int64  \n",
      " 13  Hispanic              64360 non-null  int64  \n",
      " 14  Other_race            64360 non-null  int64  \n",
      " 15  [0-10)                64360 non-null  int64  \n",
      " 16  [10-20)               64360 non-null  int64  \n",
      " 17  [20-30)               64360 non-null  int64  \n",
      " 18  [30-40)               64360 non-null  int64  \n",
      " 19  [40-50)               64360 non-null  int64  \n",
      " 20  [50-60)               64360 non-null  int64  \n",
      " 21  [60-70)               64360 non-null  int64  \n",
      " 22  [70-80)               64360 non-null  int64  \n",
      " 23  [80-90)               64360 non-null  int64  \n",
      " 24  [90-100)              64360 non-null  int64  \n",
      " 25  Circulatory_1         64360 non-null  int64  \n",
      " 26  Diabetes_1            64360 non-null  int64  \n",
      " 27  Digestive_1           64360 non-null  int64  \n",
      " 28  Genitourinary_1       64360 non-null  int64  \n",
      " 29  Injury_1              64360 non-null  int64  \n",
      " 30  Musculoskeletal_1     64360 non-null  int64  \n",
      " 31  Neoplasms_1           64360 non-null  int64  \n",
      " 32  Other_1               64360 non-null  int64  \n",
      " 33  Respiratory_1         64360 non-null  int64  \n",
      " 34  >200                  64360 non-null  int64  \n",
      " 35  >300                  64360 non-null  int64  \n",
      " 36  None_glu              64360 non-null  int64  \n",
      " 37  Norm_glu              64360 non-null  int64  \n",
      " 38  >7                    64360 non-null  int64  \n",
      " 39  >8                    64360 non-null  int64  \n",
      " 40  None_a1c              64360 non-null  int64  \n",
      " 41  Norm_a1c              64360 non-null  int64  \n",
      " 42  Down_metformin        64360 non-null  int64  \n",
      " 43  Steady_metformin      64360 non-null  int64  \n",
      " 44  Up_metformin          64360 non-null  int64  \n",
      " 45  Down_repaglinide      64360 non-null  int64  \n",
      " 46  Steady_repaglinide    64360 non-null  int64  \n",
      " 47  Up_repaglinide        64360 non-null  int64  \n",
      " 48  Steady_acarbose       64360 non-null  int64  \n",
      " 49  Up_acarbose           64360 non-null  int64  \n",
      " 50  Down_glipizide        64360 non-null  int64  \n",
      " 51  Steady_glipizide      64360 non-null  int64  \n",
      " 52  Up_glipizide          64360 non-null  int64  \n",
      " 53  Down_pioglitazone     64360 non-null  int64  \n",
      " 54  Steady_pioglitazone   64360 non-null  int64  \n",
      " 55  Up_pioglitazone       64360 non-null  int64  \n",
      " 56  Down_rosiglitazone    64360 non-null  int64  \n",
      " 57  Steady_rosiglitazone  64360 non-null  int64  \n",
      " 58  Up_rosiglitazone      64360 non-null  int64  \n",
      " 59  Down_insulin          64360 non-null  int64  \n",
      " 60  No_insulin            64360 non-null  int64  \n",
      " 61  Steady_insulin        64360 non-null  int64  \n",
      " 62  Up_insulin            64360 non-null  int64  \n",
      " 63  readmitted            64360 non-null  object \n",
      "dtypes: float64(7), int64(56), object(1)\n",
      "memory usage: 31.9+ MB\n"
     ]
    }
   ],
   "source": [
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>num_outpatient</th>\n",
       "      <th>num_inpatient</th>\n",
       "      <th>num_diagnoses</th>\n",
       "      <th>change</th>\n",
       "      <th>...</th>\n",
       "      <th>Steady_pioglitazone</th>\n",
       "      <th>Up_pioglitazone</th>\n",
       "      <th>Down_rosiglitazone</th>\n",
       "      <th>Steady_rosiglitazone</th>\n",
       "      <th>Up_rosiglitazone</th>\n",
       "      <th>Down_insulin</th>\n",
       "      <th>No_insulin</th>\n",
       "      <th>Steady_insulin</th>\n",
       "      <th>Up_insulin</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  diabetesMed  time_in_hospital  num_lab_procedures  num_procedures  \\\n",
       "0       1            1          0.166667            0.568627        0.000000   \n",
       "1       1            1          0.083333            0.098039        0.833333   \n",
       "2       0            1          0.083333            0.421569        0.166667   \n",
       "3       0            1          0.000000            0.490196        0.000000   \n",
       "4       0            1          0.166667            0.294118        1.000000   \n",
       "\n",
       "   num_medications  num_outpatient  num_inpatient  num_diagnoses  change  ...  \\\n",
       "0         0.435897        0.000000            0.0       0.636364       1  ...   \n",
       "1         0.307692        0.666667            0.5       0.363636       0  ...   \n",
       "2         0.384615        0.000000            0.0       0.454545       1  ...   \n",
       "3         0.179487        0.000000            0.0       0.272727       1  ...   \n",
       "4         0.384615        0.000000            0.0       0.636364       0  ...   \n",
       "\n",
       "   Steady_pioglitazone  Up_pioglitazone  Down_rosiglitazone  \\\n",
       "0                    0                0                   0   \n",
       "1                    0                0                   0   \n",
       "2                    0                0                   0   \n",
       "3                    0                0                   0   \n",
       "4                    0                0                   0   \n",
       "\n",
       "   Steady_rosiglitazone  Up_rosiglitazone  Down_insulin  No_insulin  \\\n",
       "0                     0                 0             0           0   \n",
       "1                     0                 0             0           1   \n",
       "2                     0                 0             0           0   \n",
       "3                     0                 0             0           0   \n",
       "4                     0                 0             0           0   \n",
       "\n",
       "   Steady_insulin  Up_insulin  readmitted  \n",
       "0               0           1         YES  \n",
       "1               0           0          NO  \n",
       "2               0           1          NO  \n",
       "3               1           0          NO  \n",
       "4               1           0         YES  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # precision recall curve - archived\n",
    "# def precision_recall_curve(model):\n",
    "#     plot_precision_recall_curve(model, X_test, y_test)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diabetes['readmitted'].values # target variable\n",
    "X = diabetes.drop('readmitted', axis=1).values # features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initializing PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After converting the dataset to all numerical features, the table took on a large number of columns. In order to reduce dimensionality, we are using Principal Component Analysis, or PCA, on our feature variables. This makes the data easier to interpret by reducing superfluous influences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio : \n",
      "[1.26892257e-01 7.31223602e-02 6.17734712e-02 6.08983118e-02\n",
      " 5.49778184e-02 5.11779819e-02 4.66325535e-02 4.26361140e-02\n",
      " 3.90225809e-02 3.54127389e-02 3.46552713e-02 2.62549147e-02\n",
      " 2.41814494e-02 2.28730260e-02 2.14368018e-02 2.06446811e-02\n",
      " 1.88580270e-02 1.77557944e-02 1.59202279e-02 1.49032415e-02\n",
      " 1.42871412e-02 1.41350728e-02 1.39895054e-02 1.34459978e-02\n",
      " 1.21426627e-02 1.13463475e-02 9.97516799e-03 9.63986704e-03\n",
      " 8.84150073e-03 8.62847585e-03 8.22213194e-03 7.74910879e-03\n",
      " 7.00806550e-03 6.47265596e-03 5.74134473e-03 5.51075417e-03\n",
      " 4.23580649e-03 3.89193144e-03 3.61808967e-03 3.45611070e-03\n",
      " 2.56913277e-03 2.53425851e-03 2.36888395e-03 1.91602574e-03\n",
      " 1.68500899e-03 1.51504575e-03 1.25397669e-03 1.06998969e-03\n",
      " 5.64762291e-04 5.46049954e-04 4.08321716e-04 4.07088848e-04\n",
      " 2.40907048e-04 2.23050360e-04 2.06119368e-04 8.95318087e-05\n",
      " 3.44850323e-05 3.46867952e-32 1.21786656e-32 6.79371339e-33\n",
      " 2.26715626e-33 1.44538420e-33 1.30875407e-33]\n",
      "Number of components = 63\n"
     ]
    }
   ],
   "source": [
    "# reduce dimensionality using PCA\n",
    "pca = PCA(random_state=42)\n",
    "pca.fit(X)\n",
    "exp_variance = pca.explained_variance_ratio_\n",
    "\n",
    "print('Explained variance ratio : \\n{}'.format(pca.explained_variance_ratio_))\n",
    "print('Number of components = {}'.format(pca.n_components_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the explained variance using a barplot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.bar(range(pca.n_components_), exp_variance)\n",
    "ax.set_xlabel('Principal Component #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate cumulative explained variance\n",
    "cum_exp_variance = np.cumsum(exp_variance)\n",
    "\n",
    "# plotting cumulative explained variance and draw a dashed line at 0.95, representing 95% of explained variance\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(cum_exp_variance)\n",
    "ax.axhline(y=0.95, linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_components where ~95% of variance is explainable\n",
    "n_components = 34\n",
    "\n",
    "# initialize PCA and project data onto components\n",
    "pca = PCA(n_components, random_state=42)\n",
    "pca.fit(X)\n",
    "pca_X = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45052, 34) (45052,)\n",
      "(19308, 34) (19308,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   21.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameter tuning - C\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(logreg, parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "clf.fit(pca_X, y).best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.6216150226405043\n",
      "Accuracy Score, Test Set:  0.621089703749741\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.63      0.91      0.74     11713\n",
      "         YES       0.56      0.18      0.27      7595\n",
      "\n",
      "    accuracy                           0.62     19308\n",
      "   macro avg       0.59      0.54      0.51     19308\n",
      "weighted avg       0.60      0.62      0.56     19308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42, C=10)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_pred = logreg.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test, logreg_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 5,\n",
       " 'min_samples_leaf': 6,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2, 4, 5, 8, 10]\n",
    "min_samples_split = [2, 4, 8, 10]\n",
    "min_samples_leaf = [2, 4, 6, 8]\n",
    "\n",
    "parameters = dict(max_depth=max_depth, criterion=criterion, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "dt_gs = GridSearchCV(decision_tree, parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "dt_gs.fit(pca_X, y).best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.6257213886175974\n",
      "Accuracy Score, Test Set: 0.617930391547545\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.63      0.92      0.75     11713\n",
      "         YES       0.55      0.15      0.23      7595\n",
      "\n",
      "    accuracy                           0.62     19308\n",
      "   macro avg       0.59      0.54      0.49     19308\n",
      "weighted avg       0.60      0.62      0.54     19308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42, criterion='gini', max_depth=5, min_samples_leaf=6, min_samples_split=2)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "decision_tree_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: {}'.format(decision_tree.score(X_train, y_train)))\n",
    "print('Accuracy Score, Test Set: {}'.format(decision_tree.score(X_test, y_test)))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test, decision_tree_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parameter tuning - takes a long time to run\n",
    "# criterion = ['gini', 'entropy']\n",
    "# n_estimators = [100, 150, 200, 250]\n",
    "# max_depth = [10, 15, 20, 25]\n",
    "\n",
    "# parameters = dict(criterion=criterion, n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "# forest = RandomForestClassifier(random_state=42)\n",
    "# forest_gs = GridSearchCV(forest, parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "# forest_gs.fit(pca_X, y).best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.6677173044481932\n",
      "Accuracy Score, Test Set: 0.6203646157033355\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.62      0.94      0.75     11713\n",
      "         YES       0.58      0.13      0.22      7595\n",
      "\n",
      "    accuracy                           0.62     19308\n",
      "   macro avg       0.60      0.53      0.48     19308\n",
      "weighted avg       0.61      0.62      0.54     19308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=42, criterion='entropy', max_depth=10, n_estimators=200)\n",
    "forest.fit(X_train, y_train)\n",
    "forest_pred = forest.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', forest.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', forest.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test, forest_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.6492497558376986\n",
      "Accuracy Score, Test Set: 0.619276983633727\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.63      0.92      0.75     11713\n",
      "         YES       0.56      0.16      0.25      7595\n",
      "\n",
      "    accuracy                           0.62     19308\n",
      "   macro avg       0.59      0.54      0.50     19308\n",
      "weighted avg       0.60      0.62      0.55     19308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "svc = SVC(random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "svc_pred = svc.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', svc.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', svc.score(X_test, y_test))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test, svc_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Under Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random under sampler method randomly (but not too random, we set the random state to 42 for consistent results) removes samples from the majority class until its size is equal to the minority class. We then train and test our models using this new set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random undersampling Counter({'NO': 25318, 'YES': 25318})\n",
      "(35445, 34) (35445,)\n",
      "(15191, 34) (15191,)\n"
     ]
    }
   ],
   "source": [
    "# separate features and target variable\n",
    "y = diabetes['readmitted'].values # target variable\n",
    "X = diabetes.drop('readmitted', axis=1).values # features\n",
    "\n",
    "# initialize\n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = under_sampler.fit_sample(X, y)\n",
    "\n",
    "print('Random undersampling {}'.format(Counter(y_rus)))\n",
    "\n",
    "# perform PCA on features\n",
    "X_rus = pca.fit_transform(X_rus)\n",
    "\n",
    "# refine train, test, split\n",
    "X_train_rus, X_test_rus, y_train_rus, y_test_rus = train_test_split(X_rus, y_rus, test_size=0.3, random_state=42, stratify=y_rus)\n",
    "\n",
    "print(X_train_rus.shape, y_train_rus.shape)\n",
    "print(X_test_rus.shape, y_test_rus.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parameter tuning - C=0.001\n",
    "# logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "# parameters = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "# clf = GridSearchCV(logreg, parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "# clf.fit(X_rus, y_rus).best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.5741571448723374\n",
      "Accuracy Score, Test Set:  0.5719834112303338\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.57      0.58      0.57      7596\n",
      "         YES       0.57      0.57      0.57      7595\n",
      "\n",
      "    accuracy                           0.57     15191\n",
      "   macro avg       0.57      0.57      0.57     15191\n",
      "weighted avg       0.57      0.57      0.57     15191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42, C=0.001)\n",
    "logreg.fit(X_train_rus, y_train_rus)\n",
    "logreg_pred = logreg.predict(X_test_rus)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train_rus, y_train_rus))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test_rus, y_test_rus))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_rus, logreg_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parameter tuning - takes a long time\n",
    "# decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# criterion = ['gini', 'entropy']\n",
    "# max_depth = [2, 4, 5, 8, 10]\n",
    "# min_samples_split = [2, 8, 14, 16]\n",
    "# min_samples_leaf = [1, 2, 4, 6]\n",
    "\n",
    "# parameters = dict(max_depth=max_depth, criterion=criterion, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "# dt_gs = GridSearchCV(decision_tree, parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "# dt_gs.fit(X_rus, y_rus).best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.5643673296656793\n",
      "Accuracy Score, Test Set: 0.5593443486274768\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.56      0.52      0.54      7596\n",
      "         YES       0.55      0.60      0.58      7595\n",
      "\n",
      "    accuracy                           0.56     15191\n",
      "   macro avg       0.56      0.56      0.56     15191\n",
      "weighted avg       0.56      0.56      0.56     15191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42, criterion='entropy', max_depth=5, min_samples_leaf=2, min_samples_split=2)\n",
    "decision_tree.fit(X_train_rus, y_train_rus)\n",
    "decision_tree_pred = decision_tree.predict(X_test_rus)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: {}'.format(decision_tree.score(X_train_rus, y_train_rus)))\n",
    "print('Accuracy Score, Test Set: {}'.format(decision_tree.score(X_test_rus, y_test_rus)))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_rus, decision_tree_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parameter tuning - takes a long time\n",
    "# forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# criterion = ['gini', 'entropy']\n",
    "# n_estimators = [50, 80, 100, 140, 200]\n",
    "# max_depth = [10, 15, 18, 20, 30]\n",
    "\n",
    "# parameters = dict(criterion=criterion, n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "# forest_gs = GridSearchCV(forest, parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "# forest_gs.fit(X_rus, y_rus).best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.7242770489490761\n",
      "Accuracy Score, Test Set: 0.5811335659271938\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.58      0.59      0.59      7596\n",
      "         YES       0.58      0.57      0.58      7595\n",
      "\n",
      "    accuracy                           0.58     15191\n",
      "   macro avg       0.58      0.58      0.58     15191\n",
      "weighted avg       0.58      0.58      0.58     15191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=42, criterion='entropy', max_depth=10, n_estimators=200)\n",
    "forest.fit(X_train_rus, y_train_rus)\n",
    "forest_pred = forest.predict(X_test_rus)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', forest.score(X_train_rus, y_train_rus))\n",
    "print('Accuracy Score, Test Set:', forest.score(X_test_rus, y_test_rus))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_rus, forest_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.570094512625194\n",
      "Accuracy Score, Test Set: 0.5700085576986373\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.56      0.61      0.59      7596\n",
      "         YES       0.58      0.53      0.55      7595\n",
      "\n",
      "    accuracy                           0.57     15191\n",
      "   macro avg       0.57      0.57      0.57     15191\n",
      "weighted avg       0.57      0.57      0.57     15191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train_rus, y_train_rus)\n",
    "gaussian_pred = gaussian.predict(X_test_rus)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train_rus, y_train_rus))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test_rus, y_test_rus))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_rus, gaussian_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.6409648751586966\n",
      "Accuracy Score, Test Set: 0.5721808965835034\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.57      0.57      0.57      7596\n",
      "         YES       0.57      0.57      0.57      7595\n",
      "\n",
      "    accuracy                           0.57     15191\n",
      "   macro avg       0.57      0.57      0.57     15191\n",
      "weighted avg       0.57      0.57      0.57     15191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "svc = SVC(random_state=42)\n",
    "svc.fit(X_train_rus, y_train_rus)\n",
    "svc_pred = svc.predict(X_test_rus)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', svc.score(X_train_rus, y_train_rus))\n",
    "print('Accuracy Score, Test Set:', svc.score(X_test_rus, y_test_rus))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_rus, svc_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edited Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'YES': 25318, 'NO': 10348})\n",
      "(24966, 34) (24966,)\n",
      "(10700, 34) (10700,)\n"
     ]
    }
   ],
   "source": [
    "y = diabetes['readmitted'].values # target variable\n",
    "X = diabetes.drop('readmitted', axis=1).values # features\n",
    "\n",
    "# initialize\n",
    "enn = EditedNearestNeighbours()\n",
    "X_enn, y_enn = enn.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_enn)))\n",
    "\n",
    "# apply PCA to features\n",
    "X_enn = pca.fit_transform(X_enn)\n",
    "\n",
    "# train test split\n",
    "X_train_enn, X_test_enn, y_train_enn, y_test_enn = train_test_split(X_enn, y_enn, test_size=0.3, random_state=42, stratify=y_enn)\n",
    "\n",
    "print(X_train_enn.shape, y_train_enn.shape)\n",
    "print(X_test_enn.shape, y_test_enn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parameter tuning - C\n",
    "# logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "# parameters = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "# clf = GridSearchCV(logreg, parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "# clf.fit(X_enn, y_enn).best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.7287911559721221\n",
      "Accuracy Score, Test Set:  0.7281308411214953\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.60      0.20      0.29      3104\n",
      "         YES       0.74      0.95      0.83      7596\n",
      "\n",
      "    accuracy                           0.73     10700\n",
      "   macro avg       0.67      0.57      0.56     10700\n",
      "weighted avg       0.70      0.73      0.68     10700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train_enn, y_train_enn)\n",
    "logreg_pred = logreg.predict(X_test_enn)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train_enn, y_train_enn))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test_enn, y_test_enn))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_enn, logreg_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.72422494592646\n",
      "Accuracy Score, Test Set: 0.7176635514018691\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.55      0.15      0.23      3104\n",
      "         YES       0.73      0.95      0.83      7596\n",
      "\n",
      "    accuracy                           0.72     10700\n",
      "   macro avg       0.64      0.55      0.53     10700\n",
      "weighted avg       0.68      0.72      0.65     10700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42, criterion='gini', max_depth=5, min_samples_leaf=4, min_samples_split=2)\n",
    "decision_tree.fit(X_train_enn, y_train_enn)\n",
    "decision_tree_pred = decision_tree.predict(X_test_enn)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: {}'.format(decision_tree.score(X_train_enn, y_train_enn)))\n",
    "print('Accuracy Score, Test Set: {}'.format(decision_tree.score(X_test_enn, y_test_enn)))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_enn, decision_tree_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random forest\n",
    "# forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# # parameter tuning\n",
    "# criterion = ['gini', 'entropy']\n",
    "# n_estimators = [100, 200, 350, 400]\n",
    "# max_depth = [10, 15, 20, 30]\n",
    "\n",
    "# parameters = dict(criterion=criterion, n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "# forest_gs = GridSearchCV(forest, parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "# forest_gs.fit(X_enn, y_enn).best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.783625730994152\n",
      "Accuracy Score, Test Set: 0.7414953271028037\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.76      0.16      0.26      3104\n",
      "         YES       0.74      0.98      0.84      7596\n",
      "\n",
      "    accuracy                           0.74     10700\n",
      "   macro avg       0.75      0.57      0.55     10700\n",
      "weighted avg       0.75      0.74      0.67     10700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=42, criterion='gini', max_depth=10, n_estimators=200)\n",
    "forest.fit(X_train_enn, y_train_enn)\n",
    "forest_pred = forest.predict(X_test_enn)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', forest.score(X_train_enn, y_train_enn))\n",
    "print('Accuracy Score, Test Set:', forest.score(X_test_enn, y_test_enn))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_enn, forest_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.6852118881679083\n",
      "Accuracy Score, Test Set: 0.6833644859813084\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.45      0.40      0.43      3104\n",
      "         YES       0.77      0.80      0.78      7596\n",
      "\n",
      "    accuracy                           0.68     10700\n",
      "   macro avg       0.61      0.60      0.60     10700\n",
      "weighted avg       0.67      0.68      0.68     10700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train_enn, y_train_enn)\n",
    "gaussian_pred = gaussian.predict(X_test_enn)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train_enn, y_train_enn))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test_enn, y_test_enn))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_enn, gaussian_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.7683649763678603\n",
      "Accuracy Score, Test Set: 0.748785046728972\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.69      0.24      0.36      3104\n",
      "         YES       0.76      0.96      0.84      7596\n",
      "\n",
      "    accuracy                           0.75     10700\n",
      "   macro avg       0.72      0.60      0.60     10700\n",
      "weighted avg       0.74      0.75      0.70     10700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "svc = SVC(random_state=42)\n",
    "svc.fit(X_train_enn, y_train_enn)\n",
    "svc_pred = svc.predict(X_test_enn)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', svc.score(X_train_enn, y_train_enn))\n",
    "print('Accuracy Score, Test Set:', svc.score(X_test_enn, y_test_enn))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_enn, svc_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parameter tuning - takes a long time\n",
    "# gamma = [0.1, 1, 10, 100]\n",
    "# C = [0.1, 1, 10, 100]\n",
    "\n",
    "# parameters = dict(gamma=gamma, C=C)\n",
    "\n",
    "# grid_svc = GridSearchCV(svc, parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "# grid_svc.fit(X_enn, y_enn).best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Near Miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'NO': 25318, 'YES': 25318})\n",
      "(35445, 34) (35445,)\n",
      "(15191, 34) (15191,)\n"
     ]
    }
   ],
   "source": [
    "y = diabetes['readmitted'].values # target variable\n",
    "X = diabetes.drop('readmitted', axis=1).values # features\n",
    "\n",
    "nm = NearMiss()\n",
    "X_nm, y_nm = nm.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_nm)))\n",
    "\n",
    "# perform PCA on features\n",
    "X_nm = pca.fit_transform(X_nm)\n",
    "\n",
    "# train test split\n",
    "X_train_nm, X_test_nm, y_train_nm, y_test_nm = train_test_split(X_nm, y_nm, test_size=0.3, random_state=42, stratify=y_nm)\n",
    "\n",
    "print(X_train_nm.shape, y_train_nm.shape)\n",
    "print(X_test_nm.shape, y_test_nm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.6354633939906899\n",
      "Accuracy Score, Test Set:  0.6268843394114937\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.62      0.67      0.64      7596\n",
      "         YES       0.64      0.58      0.61      7595\n",
      "\n",
      "    accuracy                           0.63     15191\n",
      "   macro avg       0.63      0.63      0.63     15191\n",
      "weighted avg       0.63      0.63      0.63     15191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train_nm, y_train_nm)\n",
    "logreg_pred = logreg.predict(X_test_nm)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test_nm, y_test_nm))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_nm, logreg_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.6129778530117083\n",
      "Accuracy Score, Test Set: 0.5958133105128036\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.62      0.51      0.56      7596\n",
      "         YES       0.58      0.68      0.63      7595\n",
      "\n",
      "    accuracy                           0.60     15191\n",
      "   macro avg       0.60      0.60      0.59     15191\n",
      "weighted avg       0.60      0.60      0.59     15191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42, criterion='gini', max_depth=5, min_samples_leaf=6, min_samples_split=2)\n",
    "decision_tree.fit(X_train_nm, y_train_nm)\n",
    "decision_tree_pred = decision_tree.predict(X_test_nm)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: {}'.format(decision_tree.score(X_train_nm, y_train_nm)))\n",
    "print('Accuracy Score, Test Set: {}'.format(decision_tree.score(X_test_nm, y_test_nm)))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_nm, decision_tree_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.9999153618281845\n",
      "Accuracy Score, Test Set: 0.6216180633269699\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.62      0.65      0.63      7596\n",
      "         YES       0.63      0.60      0.61      7595\n",
      "\n",
      "    accuracy                           0.62     15191\n",
      "   macro avg       0.62      0.62      0.62     15191\n",
      "weighted avg       0.62      0.62      0.62     15191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=42, criterion='gini', max_depth=35, n_estimators=450)\n",
    "forest.fit(X_train_nm, y_train_nm)\n",
    "forest_pred = forest.predict(X_test_nm)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', forest.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set:', forest.score(X_test_nm, y_test_nm))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_nm, forest_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.6271688531527719\n",
      "Accuracy Score, Test Set: 0.6177341847146337\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.59      0.75      0.66      7596\n",
      "         YES       0.66      0.48      0.56      7595\n",
      "\n",
      "    accuracy                           0.62     15191\n",
      "   macro avg       0.63      0.62      0.61     15191\n",
      "weighted avg       0.63      0.62      0.61     15191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train_nm, y_train_nm)\n",
    "gaussian_pred = gaussian.predict(X_test_nm)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test_nm, y_test_nm))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_nm, gaussian_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.6857102553251516\n",
      "Accuracy Score, Test Set: 0.640050029622803\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.61      0.76      0.68      7596\n",
      "         YES       0.68      0.52      0.59      7595\n",
      "\n",
      "    accuracy                           0.64     15191\n",
      "   macro avg       0.65      0.64      0.63     15191\n",
      "weighted avg       0.65      0.64      0.63     15191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(random_state=42)\n",
    "svc.fit(X_train_nm, y_train_nm)\n",
    "svc_pred = svc.predict(X_test_nm)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', svc.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set:', svc.score(X_test_nm, y_test_nm))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_nm, svc_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
