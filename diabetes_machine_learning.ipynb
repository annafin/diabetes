{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Overview - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this binary classification problem, we are using Logistic Regression, Decision Tree Classifier, Random Forest Classifier, and Gradient Boosting Classifier, Gaussian Naive Bayes. To assess the accuracy, we look at the accuracy scores and classification reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import (cross_val_score, \n",
    "                                     GridSearchCV, \n",
    "                                     train_test_split,  \n",
    "                                     KFold)\n",
    "from sklearn.metrics import (classification_report,\n",
    "                             confusion_matrix, \n",
    "                             accuracy_score)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier)\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetes_ml_scale.csv', index_col=0) # import data\n",
    "diabetes = data.copy() # save a copy of data as diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 64360 entries, 0 to 64359\n",
      "Data columns (total 64 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   gender                64360 non-null  int64  \n",
      " 1   diabetesMed           64360 non-null  int64  \n",
      " 2   time_in_hospital      64360 non-null  float64\n",
      " 3   num_lab_procedures    64360 non-null  float64\n",
      " 4   num_procedures        64360 non-null  float64\n",
      " 5   num_medications       64360 non-null  float64\n",
      " 6   num_outpatient        64360 non-null  float64\n",
      " 7   num_inpatient         64360 non-null  float64\n",
      " 8   num_diagnoses         64360 non-null  float64\n",
      " 9   change                64360 non-null  int64  \n",
      " 10  AfricanAmerican       64360 non-null  int64  \n",
      " 11  Asian                 64360 non-null  int64  \n",
      " 12  Caucasian             64360 non-null  int64  \n",
      " 13  Hispanic              64360 non-null  int64  \n",
      " 14  Other_race            64360 non-null  int64  \n",
      " 15  [0-10)                64360 non-null  int64  \n",
      " 16  [10-20)               64360 non-null  int64  \n",
      " 17  [20-30)               64360 non-null  int64  \n",
      " 18  [30-40)               64360 non-null  int64  \n",
      " 19  [40-50)               64360 non-null  int64  \n",
      " 20  [50-60)               64360 non-null  int64  \n",
      " 21  [60-70)               64360 non-null  int64  \n",
      " 22  [70-80)               64360 non-null  int64  \n",
      " 23  [80-90)               64360 non-null  int64  \n",
      " 24  [90-100)              64360 non-null  int64  \n",
      " 25  Circulatory_1         64360 non-null  int64  \n",
      " 26  Diabetes_1            64360 non-null  int64  \n",
      " 27  Digestive_1           64360 non-null  int64  \n",
      " 28  Genitourinary_1       64360 non-null  int64  \n",
      " 29  Injury_1              64360 non-null  int64  \n",
      " 30  Musculoskeletal_1     64360 non-null  int64  \n",
      " 31  Neoplasms_1           64360 non-null  int64  \n",
      " 32  Other_1               64360 non-null  int64  \n",
      " 33  Respiratory_1         64360 non-null  int64  \n",
      " 34  >200                  64360 non-null  int64  \n",
      " 35  >300                  64360 non-null  int64  \n",
      " 36  None_glu              64360 non-null  int64  \n",
      " 37  Norm_glu              64360 non-null  int64  \n",
      " 38  >7                    64360 non-null  int64  \n",
      " 39  >8                    64360 non-null  int64  \n",
      " 40  None_a1c              64360 non-null  int64  \n",
      " 41  Norm_a1c              64360 non-null  int64  \n",
      " 42  Down_metformin        64360 non-null  int64  \n",
      " 43  Steady_metformin      64360 non-null  int64  \n",
      " 44  Up_metformin          64360 non-null  int64  \n",
      " 45  Down_repaglinide      64360 non-null  int64  \n",
      " 46  Steady_repaglinide    64360 non-null  int64  \n",
      " 47  Up_repaglinide        64360 non-null  int64  \n",
      " 48  Steady_acarbose       64360 non-null  int64  \n",
      " 49  Up_acarbose           64360 non-null  int64  \n",
      " 50  Down_glipizide        64360 non-null  int64  \n",
      " 51  Steady_glipizide      64360 non-null  int64  \n",
      " 52  Up_glipizide          64360 non-null  int64  \n",
      " 53  Down_pioglitazone     64360 non-null  int64  \n",
      " 54  Steady_pioglitazone   64360 non-null  int64  \n",
      " 55  Up_pioglitazone       64360 non-null  int64  \n",
      " 56  Down_rosiglitazone    64360 non-null  int64  \n",
      " 57  Steady_rosiglitazone  64360 non-null  int64  \n",
      " 58  Up_rosiglitazone      64360 non-null  int64  \n",
      " 59  Down_insulin          64360 non-null  int64  \n",
      " 60  No_insulin            64360 non-null  int64  \n",
      " 61  Steady_insulin        64360 non-null  int64  \n",
      " 62  Up_insulin            64360 non-null  int64  \n",
      " 63  readmitted            64360 non-null  object \n",
      "dtypes: float64(7), int64(56), object(1)\n",
      "memory usage: 31.9+ MB\n"
     ]
    }
   ],
   "source": [
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>num_outpatient</th>\n",
       "      <th>num_inpatient</th>\n",
       "      <th>num_diagnoses</th>\n",
       "      <th>change</th>\n",
       "      <th>...</th>\n",
       "      <th>Steady_pioglitazone</th>\n",
       "      <th>Up_pioglitazone</th>\n",
       "      <th>Down_rosiglitazone</th>\n",
       "      <th>Steady_rosiglitazone</th>\n",
       "      <th>Up_rosiglitazone</th>\n",
       "      <th>Down_insulin</th>\n",
       "      <th>No_insulin</th>\n",
       "      <th>Steady_insulin</th>\n",
       "      <th>Up_insulin</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  diabetesMed  time_in_hospital  num_lab_procedures  num_procedures  \\\n",
       "0       1            1          0.166667            0.568627        0.000000   \n",
       "1       1            1          0.083333            0.098039        0.833333   \n",
       "2       0            1          0.083333            0.421569        0.166667   \n",
       "3       0            1          0.000000            0.490196        0.000000   \n",
       "4       0            1          0.166667            0.294118        1.000000   \n",
       "\n",
       "   num_medications  num_outpatient  num_inpatient  num_diagnoses  change  ...  \\\n",
       "0         0.435897        0.000000            0.0       0.636364       1  ...   \n",
       "1         0.307692        0.666667            0.5       0.363636       0  ...   \n",
       "2         0.384615        0.000000            0.0       0.454545       1  ...   \n",
       "3         0.179487        0.000000            0.0       0.272727       1  ...   \n",
       "4         0.384615        0.000000            0.0       0.636364       0  ...   \n",
       "\n",
       "   Steady_pioglitazone  Up_pioglitazone  Down_rosiglitazone  \\\n",
       "0                    0                0                   0   \n",
       "1                    0                0                   0   \n",
       "2                    0                0                   0   \n",
       "3                    0                0                   0   \n",
       "4                    0                0                   0   \n",
       "\n",
       "   Steady_rosiglitazone  Up_rosiglitazone  Down_insulin  No_insulin  \\\n",
       "0                     0                 0             0           0   \n",
       "1                     0                 0             0           1   \n",
       "2                     0                 0             0           0   \n",
       "3                     0                 0             0           0   \n",
       "4                     0                 0             0           0   \n",
       "\n",
       "   Steady_insulin  Up_insulin  readmitted  \n",
       "0               0           1         YES  \n",
       "1               0           0          NO  \n",
       "2               0           1          NO  \n",
       "3               1           0          NO  \n",
       "4               1           0         YES  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45052, 63) (45052,)\n",
      "(19308, 63) (19308,)\n"
     ]
    }
   ],
   "source": [
    "# separate variables\n",
    "y = diabetes['readmitted'].values # target variable\n",
    "X = diabetes.drop('readmitted', axis=1).values\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.622458492408772\n",
      "Accuracy Score, Test Set:  0.6203128237000207\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.63      0.92      0.74     11655\n",
      "         YES       0.57      0.17      0.26      7653\n",
      "\n",
      "    accuracy                           0.62     19308\n",
      "   macro avg       0.60      0.54      0.50     19308\n",
      "weighted avg       0.60      0.62      0.55     19308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_pred = logreg.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[10670   985]\n",
      " [ 6346  1307]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, logreg_pred)\n",
    "print('Confusion Matrix \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 42,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   10.4s finished\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameter tuning - C\n",
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(logreg, parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "clf.fit(X, y).best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.6223475095445263\n",
      "Accuracy Score, Test Set: 0.6206753677232235\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.63      0.92      0.74     11655\n",
      "         YES       0.57      0.17      0.26      7653\n",
      "\n",
      "    accuracy                           0.62     19308\n",
      "   macro avg       0.60      0.54      0.50     19308\n",
      "weighted avg       0.61      0.62      0.55     19308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using new parameters\n",
    "logreg = LogisticRegression(random_state=42, C=0.1)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_pred = logreg.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: {}'.format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy Score, Test Set: {}'.format(logreg.score(X_test, y_test)))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[10697   958]\n",
      " [ 6366  1287]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print('Confusion Matrix \\n', confusion_matrix(y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.9999334102814526\n",
      "Accuracy Score, Test Set: 0.5475968510461985\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.63      0.62      0.62     11655\n",
      "         YES       0.43      0.44      0.43      7653\n",
      "\n",
      "    accuracy                           0.55     19308\n",
      "   macro avg       0.53      0.53      0.53     19308\n",
      "weighted avg       0.55      0.55      0.55     19308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "decision_tree_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: {}'.format(decision_tree.score(X_train, y_train)))\n",
    "print('Accuracy Score, Test Set: {}'.format(decision_tree.score(X_test, y_test)))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, decision_tree_pred)) # very overfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[7226 4429]\n",
      " [4306 3347]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print('Confusion Matrix \\n', confusion_matrix(y_test, decision_tree_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree Classifier training set is very over fitted compared to the test set, which means that we have to tune the model's parameters so that it is learning the data instead of memorizing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are focused on the criterion, max_depth, and min_samples_split parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': 42,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   45.0s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 5,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2, 4, 5, 8, 10]\n",
    "min_samples_split = [2, 8, 14, 16]\n",
    "min_samples_leaf = [1, 2, 4, 6]\n",
    "\n",
    "parameters = dict(max_depth=max_depth, criterion=criterion, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "dt_gs = GridSearchCV(decision_tree, parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "dt_gs.fit(X_train, y_train).best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.6267646275415076\n",
      "Accuracy Score, Test Set: 0.6206753677232235\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.63      0.90      0.74     11655\n",
      "         YES       0.56      0.19      0.28      7653\n",
      "\n",
      "    accuracy                           0.62     19308\n",
      "   macro avg       0.60      0.55      0.51     19308\n",
      "weighted avg       0.60      0.62      0.56     19308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using new parameters - overfitting problem reduced\n",
    "decision_tree = DecisionTreeClassifier(random_state=42, criterion='gini', max_depth=5, min_samples_leaf=4, min_samples_split=2)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "decision_tree_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', decision_tree.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', decision_tree.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, decision_tree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[10540  1115]\n",
      " [ 6209  1444]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print('Confusion Matrix \\n', confusion_matrix(y_test, decision_tree_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validation - k folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \n",
      "Accuracy Score, Training Set: 0.6304187383467993\n",
      "Accuracy Score, Test Set: 0.598430702299565\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.59      0.94      0.73      7305\n",
      "         YES       0.66      0.15      0.24      5567\n",
      "\n",
      "    accuracy                           0.60     12872\n",
      "   macro avg       0.63      0.54      0.48     12872\n",
      "weighted avg       0.62      0.60      0.52     12872\n",
      "\n",
      "Iteration: \n",
      "Accuracy Score, Training Set: 0.6132885332504662\n",
      "Accuracy Score, Test Set: 0.6629894344313239\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.67      0.92      0.78      8192\n",
      "         YES       0.60      0.22      0.32      4680\n",
      "\n",
      "    accuracy                           0.66     12872\n",
      "   macro avg       0.64      0.57      0.55     12872\n",
      "weighted avg       0.65      0.66      0.61     12872\n",
      "\n",
      "Iteration: \n",
      "Accuracy Score, Training Set: 0.6459174953387197\n",
      "Accuracy Score, Test Set: 0.5299098819142325\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.52      0.94      0.67      6642\n",
      "         YES       0.59      0.09      0.16      6230\n",
      "\n",
      "    accuracy                           0.53     12872\n",
      "   macro avg       0.56      0.52      0.42     12872\n",
      "weighted avg       0.56      0.53      0.43     12872\n",
      "\n",
      "Iteration: \n",
      "Accuracy Score, Training Set: 0.6282434742075823\n",
      "Accuracy Score, Test Set: 0.6095400870105656\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.62      0.88      0.73      7636\n",
      "         YES       0.55      0.22      0.31      5236\n",
      "\n",
      "    accuracy                           0.61     12872\n",
      "   macro avg       0.59      0.55      0.52     12872\n",
      "weighted avg       0.59      0.61      0.56     12872\n",
      "\n",
      "Iteration: \n",
      "Accuracy Score, Training Set: 0.6076755748912368\n",
      "Accuracy Score, Test Set: 0.6785270354257302\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.74      0.86      0.79      9267\n",
      "         YES       0.37      0.22      0.27      3605\n",
      "\n",
      "    accuracy                           0.68     12872\n",
      "   macro avg       0.56      0.54      0.53     12872\n",
      "weighted avg       0.64      0.68      0.65     12872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5) # split into 5 folds \n",
    "kf.get_n_splits(X)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print('Iteration: ')\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    decision_tree = DecisionTreeClassifier(random_state=42, criterion='gini', max_depth=5, min_samples_leaf=4, min_samples_split=2)\n",
    "    decision_tree.fit(X_train, y_train)\n",
    "    decision_tree_pred = decision_tree.predict(X_test)\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', decision_tree.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', decision_tree.score(X_test, y_test))\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, decision_tree_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.6192316656308267\n",
      "Accuracy Score, Test Set: 0.6674953387197017\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.75      0.80      0.78      9267\n",
      "         YES       0.39      0.33      0.35      3605\n",
      "\n",
      "    accuracy                           0.67     12872\n",
      "   macro avg       0.57      0.56      0.57     12872\n",
      "weighted avg       0.65      0.67      0.66     12872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "gbc.fit(X_train, y_train)\n",
    "gbc_pred = gbc.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', gbc.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', gbc.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, gbc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[7420 1847]\n",
      " [2433 1172]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print('Confusion Matrix \\n', confusion_matrix(y_test, gbc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 3,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_iter_no_change': None,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': 42,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed: 25.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'n_estimators': 150}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# abbreviated parameter tuning\n",
    "n_estimators = [20, 50, 80, 100, 150]\n",
    "max_depth = [4, 6, 8, 10, 14]\n",
    "\n",
    "parameters = dict(n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "gbc_gs = GridSearchCV(gbc, parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "gbc_gs.fit(X_train, y_train).best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.6361482287134866\n",
      "Accuracy Score, Test Set: 0.6523461777501554\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.76      0.76      0.76      9267\n",
      "         YES       0.38      0.38      0.38      3605\n",
      "\n",
      "    accuracy                           0.65     12872\n",
      "   macro avg       0.57      0.57      0.57     12872\n",
      "weighted avg       0.65      0.65      0.65     12872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using new parameters\n",
    "gbc = GradientBoostingClassifier(random_state=42, max_depth=4, n_estimators=150)\n",
    "gbc.fit(X_train, y_train)\n",
    "gbc_pred = gbc.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', gbc.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', gbc.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, gbc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[7028 2239]\n",
      " [2236 1369]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print('Confusion Matrix \\n', confusion_matrix(y_test, gbc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.999941733996271\n",
      "Accuracy Score, Test Set: 0.6208048477315102\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.75      0.70      0.73      9267\n",
      "         YES       0.35      0.41      0.38      3605\n",
      "\n",
      "    accuracy                           0.62     12872\n",
      "   macro avg       0.55      0.56      0.55     12872\n",
      "weighted avg       0.64      0.62      0.63     12872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "forest_pred = forest.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', forest.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', forest.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, forest_pred)) # very overfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[6510 2757]\n",
      " [2124 1481]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print('Confusion Matrix \\n', confusion_matrix(y_test, forest_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original Random Forest Classifier has an over fitting problem with the training set. This can happen and therefore, we have to tune the model's parameters since it looks like the model just memorized sample structures rather than learning them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters we are tuning to optimize our model are criterion, max_depth and n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  8.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 100}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# abbreviated parameter tuning\n",
    "criterion = ['gini', 'entropy']\n",
    "n_estimators = [50, 80, 100, 140, 200]\n",
    "max_depth = [10, 15, 18, 20, 30]\n",
    "\n",
    "parameters = dict(criterion=criterion, n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "forest_gs = GridSearchCV(forest, parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "forest_gs.fit(X_train, y_train).best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.7289077066500932\n",
      "Accuracy Score, Test Set: 0.6745649471721566\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.75      0.83      0.79      9267\n",
      "         YES       0.39      0.28      0.33      3605\n",
      "\n",
      "    accuracy                           0.67     12872\n",
      "   macro avg       0.57      0.55      0.56     12872\n",
      "weighted avg       0.65      0.67      0.66     12872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using new parameters\n",
    "forest = RandomForestClassifier(random_state=42, criterion='entropy', max_depth=15, n_estimators=100)\n",
    "forest.fit(X_train, y_train)\n",
    "forest_pred = forest.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', forest.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', forest.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, forest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[7671 1596]\n",
      " [2593 1012]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print('Confusion Matrix \\n', confusion_matrix(y_test, forest_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validation - k folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \n",
      "Accuracy Score, Training Set: 0.7126320696084525\n",
      "Accuracy Score, Test Set: 0.5918272218769423\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.59      0.96      0.73      7305\n",
      "         YES       0.68      0.11      0.18      5567\n",
      "\n",
      "    accuracy                           0.59     12872\n",
      "   macro avg       0.63      0.53      0.46     12872\n",
      "weighted avg       0.63      0.59      0.49     12872\n",
      "\n",
      "Iteration: \n",
      "Accuracy Score, Training Set: 0.7108452454940957\n",
      "Accuracy Score, Test Set: 0.6518023617153511\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.66      0.91      0.77      8192\n",
      "         YES       0.56      0.19      0.29      4680\n",
      "\n",
      "    accuracy                           0.65     12872\n",
      "   macro avg       0.61      0.55      0.53     12872\n",
      "weighted avg       0.63      0.65      0.59     12872\n",
      "\n",
      "Iteration: \n",
      "Accuracy Score, Training Set: 0.7194103480422622\n",
      "Accuracy Score, Test Set: 0.5314636420136731\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.53      0.94      0.67      6642\n",
      "         YES       0.60      0.10      0.17      6230\n",
      "\n",
      "    accuracy                           0.53     12872\n",
      "   macro avg       0.56      0.52      0.42     12872\n",
      "weighted avg       0.56      0.53      0.43     12872\n",
      "\n",
      "Iteration: \n",
      "Accuracy Score, Training Set: 0.7147879117464263\n",
      "Accuracy Score, Test Set: 0.6075201988812927\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.61      0.92      0.74      7636\n",
      "         YES       0.57      0.15      0.24      5236\n",
      "\n",
      "    accuracy                           0.61     12872\n",
      "   macro avg       0.59      0.54      0.49     12872\n",
      "weighted avg       0.59      0.61      0.53     12872\n",
      "\n",
      "Iteration: \n",
      "Accuracy Score, Training Set: 0.7289077066500932\n",
      "Accuracy Score, Test Set: 0.6745649471721566\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.75      0.83      0.79      9267\n",
      "         YES       0.39      0.28      0.33      3605\n",
      "\n",
      "    accuracy                           0.67     12872\n",
      "   macro avg       0.57      0.55      0.56     12872\n",
      "weighted avg       0.65      0.67      0.66     12872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5) # split into 5 folds \n",
    "kf.get_n_splits(X)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print('Iteration: ')\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    forest = RandomForestClassifier(random_state=42, criterion='entropy', max_depth=15, n_estimators=100)\n",
    "    forest.fit(X_train, y_train)\n",
    "    forest_pred = forest.predict(X_test)\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', forest.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', forest.score(X_test, y_test))\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, forest_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.5899432877563704\n",
      "Accuracy Score, Test Set: 0.5886420136730889\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.77      0.61      0.68      9267\n",
      "         YES       0.35      0.54      0.42      3605\n",
      "\n",
      "    accuracy                           0.59     12872\n",
      "   macro avg       0.56      0.57      0.55     12872\n",
      "weighted avg       0.65      0.59      0.61     12872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, y_train)\n",
    "gaussian_pred = gaussian.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, gaussian_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[5642 3625]\n",
      " [1670 1935]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print('Confusion Matrix \\n', confusion_matrix(y_test, gaussian_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
